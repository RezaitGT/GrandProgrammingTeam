from flask import Flask, render_template, request, jsonify
import os
import uuid
import io
from werkzeug.utils import secure_filename
import re
from datetime import datetime
from PIL import Image

# –ü–æ–ø—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å PyMuPDF, –µ—Å–ª–∏ –Ω–µ—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º pdfplumber
try:
    import fitz  # PyMuPDF
    PYMUPDF_AVAILABLE = True
    print("‚úÖ PyMuPDF –¥–æ—Å—Ç—É–ø–µ–Ω")
except ImportError:
    PYMUPDF_AVAILABLE = False
    print("‚ö†Ô∏è PyMuPDF –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è pdfplumber")

try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
    print("‚úÖ PDFPlumber –¥–æ—Å—Ç—É–ø–µ–Ω")
except ImportError:
    PDFPLUMBER_AVAILABLE = False
    print("‚ö†Ô∏è PDFPlumber –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['SECRET_KEY'] = 'normcontrol-secret-key-2024'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB

# Ensure upload folder exists
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# =============================================================================
# CONFIG - –ù–æ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ –¢–ó
# =============================================================================
class Config:
    TZ_RULES = {
        "title_block": {
            "rule_1.1.1": "–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–π –Ω–∞–¥–ø–∏—Å–∏ –≤ —á–∞—Å—Ç–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ—ã 1 (–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –∏–∑–¥–µ–ª–∏—è –∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞, –µ—Å–ª–∏ —ç—Ç–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É –ø—Ä–∏—Å–≤–æ–µ–Ω –∫–æ–¥ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —ç—Ç–æ–≥–æ –∫–æ–¥–∞ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–∞)",
            "rule_1.1.2": "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –Ω–∞–¥ –æ—Å–Ω–æ–≤–Ω–æ–π –Ω–∞–¥–ø–∏—Å—å—é –∏ –Ω–µ –≤—ã—Ö–æ–¥ –∏—Ö –∑–∞ —à–∏—Ä–∏–Ω—É —Ä–∞–≤–Ω—É—é 185 –º–º"
        }
    }

# =============================================================================
# DOCUMENT ANALYZER
# =============================================================================
class DocumentAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –¢–ó
    """
    
    def __init__(self):
        # –°–ª–æ–≤–∞—Ä–∏ –∫–æ–¥–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –¢–ó
        self.document_codes = {
            # –ß–µ—Ä—Ç–µ–∂–∏
            '–°–ë': '–°–±–æ—Ä–æ—á–Ω—ã–π —á–µ—Ä—Ç–µ–∂',
            '–í–û': '–ß–µ—Ä—Ç–µ–∂ –æ–±—â–µ–≥–æ –≤–∏–¥–∞', 
            '–¢–ß': '–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–π —á–µ—Ä—Ç–µ–∂',
            '–ì–ß': '–ì–∞–±–∞—Ä–∏—Ç–Ω—ã–π —á–µ—Ä—Ç–µ–∂',
            '–ú–≠': '–≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–π —á–µ—Ä—Ç–µ–∂',
            '–ú–ß': '–ú–æ–Ω—Ç–∞–∂–Ω—ã–π —á–µ—Ä—Ç–µ–∂',
            '–£–ß': '–£–ø–∞–∫–æ–≤–æ—á–Ω—ã–π —á–µ—Ä—Ç–µ–∂',
            
            # –í–µ–¥–æ–º–æ—Å—Ç–∏
            '–í–°': '–í–µ–¥–æ–º–æ—Å—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π',
            '–í–î': '–í–µ–¥–æ–º–æ—Å—Ç—å —Å—Å—ã–ª–æ—á–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤',
            '–í–ü': '–í–µ–¥–æ–º–æ—Å—Ç—å –ø–æ–∫—É–ø–Ω—ã—Ö –∏–∑–¥–µ–ª–∏–π',
            '–í–ò': '–í–µ–¥–æ–º–æ—Å—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø–æ–∫—É–ø–Ω—ã—Ö –∏–∑–¥–µ–ª–∏–π',
            '–î–ü': '–í–µ–¥–æ–º–æ—Å—Ç—å –¥–µ—Ä–∂–∞—Ç–µ–ª–µ–π –ø–æ–¥–ª–∏–Ω–Ω–∏–∫–æ–≤',
            '–ü–¢': '–í–µ–¥–æ–º–æ—Å—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è',
            '–≠–ü': '–í–µ–¥–æ–º–æ—Å—Ç—å —ç—Å–∫–∏–∑–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞',
            '–¢–ü': '–í–µ–¥–æ–º–æ—Å—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞',
            '–í–î–≠': '–í–µ–¥–æ–º–æ—Å—Ç—å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤',
            
            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
            '–ü–ó': '–ü–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–ø–∏—Å–∫–∞',
            '–¢–£': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —É—Å–ª–æ–≤–∏—è',
            '–ü–ú': '–ü—Ä–æ–≥—Ä–∞–º–º–∞ –∏ –º–µ—Ç–æ–¥–∏–∫–∞ –∏—Å–ø—ã—Ç–∞–Ω–∏–π',
            '–¢–ë': '–¢–∞–±–ª–∏—Ü—ã',
            '–†–†': '–†–∞—Å—á–µ—Ç—ã',
            '–†–≠': '–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏',
            '–ò–ú': '–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –º–æ–Ω—Ç–∞–∂—É, –ø—É—Å–∫—É, —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—é –∏ –æ–±–∫–∞—Ç–∫–µ –∏–∑–¥–µ–ª–∏—è',
            '–§–û': '–§–æ—Ä–º—É–ª—è—Ä',
            '–ü–°': '–ü–∞—Å–ø–æ—Ä—Ç',
            '–≠–¢': '–≠—Ç–∏–∫–µ—Ç–∫–∞',
            '–ö–ò': '–ö–∞—Ç–∞–ª–æ–≥ –∏–∑–¥–µ–ª–∏—è',
            '–ù–ó–ß': '–ù–æ—Ä–º—ã —Ä–∞—Å—Ö–æ–¥–∞ –∑–∞–ø–∞—Å–Ω—ã—Ö —á–∞—Å—Ç–µ–π',
            '–ù–ú': '–ù–æ—Ä–º—ã —Ä–∞—Å—Ö–æ–¥–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤',
            '–ó–ò': '–í–µ–¥–æ–º–æ—Å—Ç—å –ó–ò–ü',
            '–£–ü': '–£—á–µ–±–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–ª–∞–∫–∞—Ç—ã',
            '–ò–°': '–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ',
            '–í–≠': '–í–µ–¥–æ–º–æ—Å—Ç—å —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤',
            
            # –†–µ–º–æ–Ω—Ç–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
            '–†–ö': '–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ä–µ–º–æ–Ω—Ç—É',
            '–†–°': '–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ä–µ–º–æ–Ω—Ç—É',
            '–£–ö': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —É—Å–ª–æ–≤–∏—è –Ω–∞ —Ä–µ–º–æ–Ω—Ç',
            '–£–°': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —É—Å–ª–æ–≤–∏—è –Ω–∞ —Ä–µ–º–æ–Ω—Ç',
            '–ó–ö': '–ù–æ—Ä–º—ã —Ä–∞—Å—Ö–æ–¥–∞ –∑–∞–ø–∞—Å–Ω—ã—Ö —á–∞—Å—Ç–µ–π –Ω–∞ —Ä–µ–º–æ–Ω—Ç',
            '–ó–°': '–ù–æ—Ä–º—ã —Ä–∞—Å—Ö–æ–¥–∞ –∑–∞–ø–∞—Å–Ω—ã—Ö —á–∞—Å—Ç–µ–π –Ω–∞ —Ä–µ–º–æ–Ω—Ç',
            '–ú–ö': '–ù–æ—Ä–º—ã —Ä–∞—Å—Ö–æ–¥–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –Ω–∞ —Ä–µ–º–æ–Ω—Ç',
            '–ú–°': '–ù–æ—Ä–º—ã —Ä–∞—Å—Ö–æ–¥–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –Ω–∞ —Ä–µ–º–æ–Ω—Ç',
            '–ó–ò–ö': '–í–µ–¥–æ–º–æ—Å—Ç—å –ó–ò–ü –Ω–∞ —Ä–µ–º–æ–Ω—Ç',
            '–ó–ò–°': '–í–µ–¥–æ–º–æ—Å—Ç—å –ó–ò–ü –Ω–∞ —Ä–µ–º–æ–Ω—Ç',
            '–í–†–ö': '–í–µ–¥–æ–º–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–µ–º–æ–Ω—Ç–∞',
            '–í–†–°': '–í–µ–¥–æ–º–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–µ–º–æ–Ω—Ç–∞'
        }
        
        self.scheme_codes = {
            # –≠–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Å—Ö–µ–º—ã
            '–≠1': '–°—Ö–µ–º–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è',
            '–≠2': '–°—Ö–µ–º–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è', 
            '–≠3': '–°—Ö–µ–º–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–∞—è',
            '–≠4': '–°—Ö–µ–º–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π',
            '–≠5': '–°—Ö–µ–º–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è',
            '–≠6': '–°—Ö–µ–º–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è –æ–±—â–∞—è',
            '–≠7': '–°—Ö–µ–º–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è',
            
            # –ì–∏–¥—Ä–∞–≤–ª–∏—á–µ—Å–∫–∏–µ —Å—Ö–µ–º—ã
            '–ì1': '–°—Ö–µ–º–∞ –≥–∏–¥—Ä–∞–≤–ª–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è',
            '–ì3': '–°—Ö–µ–º–∞ –≥–∏–¥—Ä–∞–≤–ª–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–∞—è',
            '–ì4': '–°—Ö–µ–º–∞ –≥–∏–¥—Ä–∞–≤–ª–∏—á–µ—Å–∫–∞—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è',
            
            # –ü–Ω–µ–≤–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ö–µ–º—ã
            '–ü1': '–°—Ö–µ–º–∞ –ø–Ω–µ–≤–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è',
            '–ü3': '–°—Ö–µ–º–∞ –ø–Ω–µ–≤–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–∞—è', 
            '–ü4': '–°—Ö–µ–º–∞ –ø–Ω–µ–≤–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è',
            
            # –ì–∞–∑–æ–≤—ã–µ —Å—Ö–µ–º—ã
            '–•1': '–°—Ö–µ–º–∞ –≥–∞–∑–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è',
            '–•3': '–°—Ö–µ–º–∞ –≥–∞–∑–æ–≤–∞—è –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–∞—è',
            '–•4': '–°—Ö–µ–º–∞ –≥–∞–∑–æ–≤–∞—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è',
            
            # –ö–∏–Ω–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ö–µ–º—ã
            '–ö1': '–°—Ö–µ–º–∞ –∫–∏–Ω–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è',
            '–ö2': '–°—Ö–µ–º–∞ –∫–∏–Ω–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è',
            '–ö3': '–°—Ö–µ–º–∞ –∫–∏–Ω–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–∞—è',
            
            # –í–∞–∫—É—É–º–Ω—ã–µ —Å—Ö–µ–º—ã
            '–í1': '–°—Ö–µ–º–∞ –≤–∞–∫—É—É–º–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è',
            '–í3': '–°—Ö–µ–º–∞ –≤–∞–∫—É—É–º–Ω–∞—è –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–∞—è',
            '–í4': '–°—Ö–µ–º–∞ –≤–∞–∫—É—É–º–Ω–∞—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π',
            
            # –û–ø—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ö–µ–º—ã
            '–õ3': '–°—Ö–µ–º–∞ –æ–ø—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–∞—è',
            
            # –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ö–µ–º—ã
            '–†1': '–°—Ö–µ–º–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è',
            '–†2': '–°—Ö–µ–º–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è',
            '–†3': '–°—Ö–µ–º–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–∞—è',
            '–†4': '–°—Ö–µ–º–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π',
            '–†5': '–°—Ö–µ–º–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è',
            '–†6': '–°—Ö–µ–º–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è –æ–±—â–∞—è',
            '–†7': '–°—Ö–µ–º–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è'
        }
    
    def get_all_document_codes(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∫–æ–¥—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        return {**self.document_codes, **self.scheme_codes}
    
    def extract_text_from_pdf(self, pdf_path: str) -> dict:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF
        """
        print(f"\nüîç –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –¢–ï–ö–°–¢–ê –ò–ó PDF")
        print("=" * 80)
        
        text_data = self._try_extraction_methods(pdf_path)
        self._print_detailed_content(text_data)
        
        print("=" * 80)
        print("‚úÖ –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –¢–ï–ö–°–¢–ê –ó–ê–í–ï–†–®–ï–ù–û")
        print("=" * 80)
        
        return text_data
    
    def _try_extraction_methods(self, pdf_path: str) -> dict:
        """–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""
        methods = [
            ("PyMuPDF", self._extract_with_pymupdf),
            ("PDFPlumber", self._extract_with_pdfplumber),
        ]
        
        for method_name, method_func in methods:
            print(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ –º–µ—Ç–æ–¥–∞: {method_name}")
            try:
                text_data = method_func(pdf_path)
                if self._has_significant_text(text_data):
                    print(f"‚úÖ {method_name} —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ–∫ —Ç–µ–∫—Å—Ç")
                    return text_data
            except Exception as e:
                print(f"‚ùå {method_name} –æ—à–∏–±–∫–∞: {e}")
        
        print("‚ùå –ú–µ—Ç–æ–¥—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏")
        return self._create_empty_text_data()
    
    def _extract_with_pymupdf(self, pdf_path: str) -> dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PyMuPDF"""
        doc = fitz.open(pdf_path)
        text_data = {
            'pages': [],
            'metadata': doc.metadata,
            'total_pages': doc.page_count,
            'extraction_method': 'PyMuPDF'
        }
        
        for page_num in range(doc.page_count):
            page = doc[page_num]
            text = page.get_text()
            
            page_data = {
                'page_number': page_num + 1,
                'text': text,
                'blocks': [],
                'width': page.rect.width,
                'height': page.rect.height,
            }
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —à–∏—Ä–∏–Ω—ã
            text_blocks = page.get_text("dict")["blocks"]
            for block in text_blocks:
                if "lines" in block:
                    for line in block["lines"]:
                        for span in line["spans"]:
                            block_data = {
                                'text': span['text'],
                                'bbox': span['bbox'],
                                'size': span['size'],
                                'font': span['font'],
                            }
                            page_data['blocks'].append(block_data)
            
            text_data['pages'].append(page_data)
        
        doc.close()
        return text_data
    
    def _extract_with_pdfplumber(self, pdf_path: str) -> dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PDFPlumber"""
        text_data = {
            'pages': [],
            'total_pages': 0,
            'extraction_method': 'PDFPlumber'
        }
        
        with pdfplumber.open(pdf_path) as pdf:
            text_data['total_pages'] = len(pdf.pages)
            text_data['metadata'] = {
                'producer': getattr(pdf.metadata, 'producer', ''),
                'creator': getattr(pdf.metadata, 'creator', ''),
            }
            
            for page_num, page in enumerate(pdf.pages):
                text = page.extract_text() or ""
                
                page_data = {
                    'page_number': page_num + 1,
                    'text': text,
                    'blocks': [],
                    'width': page.width,
                    'height': page.height,
                }
                text_data['pages'].append(page_data)
        
        return text_data
    
    def _print_detailed_content(self, text_data: dict):
        """–í—ã–≤–æ–¥ –≤—Å–µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ PDF"""
        print(f"üìä –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü: {text_data.get('total_pages', 0)}")
        
        for page in text_data.get('pages', []):
            page_text = page.get('text', '').strip()
            
            print(f"\nüìÑ –°–¢–†–ê–ù–ò–¶–ê {page['page_number']}:")
            print("-" * 60)
            
            if page_text:
                print(page_text)
            else:
                print("[–¢–ï–ö–°–¢ –û–¢–°–£–¢–°–¢–í–£–ï–¢]")
            
            print("-" * 60)
    
    def _has_significant_text(self, text_data: dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∑–Ω–∞—á–∏–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        total_chars = 0
        for page in text_data.get('pages', []):
            total_chars += len(page.get('text', ''))
        return total_chars > 10
    
    def _create_empty_text_data(self) -> dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö"""
        return {
            'pages': [],
            'total_pages': 0,
            'metadata': {},
            'extraction_method': 'None'
        }

# =============================================================================
# RULE ENGINE - –¢–û–õ–¨–ö–û –ü–†–û–í–ï–†–ö–ò –ò–ó –¢–ó
# =============================================================================
class RuleEngine:
    def __init__(self):
        self.tz_rules = Config.TZ_RULES
        self.document_analyzer = DocumentAnalyzer()
        
    def check_title_block_requirements(self, text_data: dict) -> list:
        """
        1.1.1 –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–π –Ω–∞–¥–ø–∏—Å–∏ - –≥—Ä–∞—Ñ–∞ 1
        """
        print(f"\nüîç –ü–†–û–í–ï–†–ö–ê 1.1.1: –û–°–ù–û–í–ù–ê–Ø –ù–ê–î–ü–ò–°–¨ - –ì–†–ê–§–ê 1")
        print("=" * 60)
        
        violations = []
        all_text = ""
        for page in text_data.get('pages', []):
            all_text += page.get('text', '') + "\n"
        
        # –ü–æ–∏—Å–∫ –∫–æ–¥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Ñ–æ—Ä–º–∞—Ç: –†–ù–ê–¢.301276.001–°–ë)
        document_code_match = re.search(r'[–ê-–Ø]{2,4}\.[0-9]+\.[0-9]+([–ê-–Ø]{2,3})', all_text)
        
        if document_code_match:
            found_code = document_code_match.group(1)
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {found_code}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–æ–¥–∞ –∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
            code_check = self._check_document_code_compliance(all_text, found_code)
            if code_check:
                violations.append(code_check)
        else:
            print("‚ùå –ö–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            violations.append({
                'rule_id': '1.1.1_code_missing',
                'rule_text': self.tz_rules['title_block']['rule_1.1.1'],
                'violation': '–ö–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –Ω–∞–¥–ø–∏—Å–∏',
                'location': '–û—Å–Ω–æ–≤–Ω–∞—è –Ω–∞–¥–ø–∏—Å—å - –≥—Ä–∞—Ñ–∞ 1',
                'severity': 'high',
                'recommendation': '–î–æ–±–∞–≤—å—Ç–µ –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ: –†–ù–ê–¢.301276.001–°–ë'
            })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –∏–∑–¥–µ–ª–∏—è
        product_name_check = self._check_product_name(all_text)
        if product_name_check:
            violations.append(product_name_check)
        
        print("=" * 60)
        return violations
    
    def _check_document_code_compliance(self, text: str, found_code: str) -> dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–æ–¥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –µ–≥–æ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è"""
        all_codes = self.document_analyzer.get_all_document_codes()
        
        if found_code in all_codes:
            expected_name = all_codes[found_code]
            print(f"‚úÖ –û–∂–∏–¥–∞–µ–º–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–æ–¥–∞ {found_code}: {expected_name}")
            
            # –ü–æ–∏—Å–∫ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ
            if expected_name.upper() not in text.upper():
                return {
                    'rule_id': '1.1.1_code_mismatch',
                    'rule_text': self.tz_rules['title_block']['rule_1.1.1'],
                    'violation': f'–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–¥—É {found_code}',
                    'location': '–û—Å–Ω–æ–≤–Ω–∞—è –Ω–∞–¥–ø–∏—Å—å - –≥—Ä–∞—Ñ–∞ 1',
                    'severity': 'high',
                    'recommendation': f'–ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ "{expected_name}" –∏–ª–∏ –∏—Å–ø—Ä–∞–≤—å—Ç–µ –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞'
                }
            else:
                print(f"‚úÖ –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–¥—É {found_code}")
        else:
            print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {found_code}")
            return {
                'rule_id': '1.1.1_unknown_code',
                'rule_text': self.tz_rules['title_block']['rule_1.1.1'],
                'violation': f'–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {found_code}',
                'location': '–û—Å–Ω–æ–≤–Ω–∞—è –Ω–∞–¥–ø–∏—Å—å - –≥—Ä–∞—Ñ–∞ 1', 
                'severity': 'medium',
                'recommendation': '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞'
            }
        
        return None
    
    def _check_product_name(self, text: str) -> dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –∏–∑–¥–µ–ª–∏—è"""
        product_patterns = [
            r'–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ[:\s]*([^\n]+)',
            r'–ò–∑–¥–µ–ª–∏–µ[:\s]*([^\n]+)',
            r'–û–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ[:\s]*([^\n]+)',
            r'^[–ê-–Ø][–ê-–Ø–∞-—è\s]+$'
        ]
        
        product_name = None
        for pattern in product_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
            if match:
                product_name = match.group(1) if match.groups() else match.group(0)
                break
        
        if product_name and len(product_name.strip()) > 2:
            print(f"‚úÖ –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–∑–¥–µ–ª–∏—è: {product_name.strip()}")
            return None
        else:
            print("‚ùå –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–∑–¥–µ–ª–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return {
                'rule_id': '1.1.1_product_name',
                'rule_text': self.tz_rules['title_block']['rule_1.1.1'],
                'violation': '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–∑–¥–µ–ª–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ',
                'location': '–û—Å–Ω–æ–≤–Ω–∞—è –Ω–∞–¥–ø–∏—Å—å - –≥—Ä–∞—Ñ–∞ 1',
                'severity': 'high',
                'recommendation': '–î–æ–±–∞–≤—å—Ç–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–∑–¥–µ–ª–∏—è –≤ –æ—Å–Ω–æ–≤–Ω—É—é –Ω–∞–¥–ø–∏—Å—å'
            }
    
    
    def run_all_checks(self, document_data: dict) -> dict:
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –∏–∑ –¢–ó"""
        all_violations = []
        
        text_data = document_data.get('text_data', {})
        
        print("üéØ –ó–ê–ü–£–°–ö –ü–†–û–í–ï–†–û–ö –ò–ó –¢–ó:")
        print("   1.1.1 - –û—Å–Ω–æ–≤–Ω–∞—è –Ω–∞–¥–ø–∏—Å—å (–∫–æ–¥ –∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ)")
        print("   1.1.2 - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (—Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∏ —à–∏—Ä–∏–Ω–∞)")
        print("=" * 60)
        
        # üî¥ –¢–û–õ–¨–ö–û –ù–û–í–´–ï –ü–†–û–í–ï–†–ö–ò –ò–ó –¢–ó
        all_violations.extend(self.check_title_block_requirements(text_data))
        #all_violations.extend(self.check_technical_requirements_placement(text_data))
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            'total_violations': len(all_violations),
            'high_severity': len([v for v in all_violations if v['severity'] == 'high']),
            'medium_severity': len([v for v in all_violations if v['severity'] == 'medium']),
            'low_severity': len([v for v in all_violations if v['severity'] == 'low'])
        }
        
        print(f"\nüìä –ò–¢–û–ì–ò –ü–†–û–í–ï–†–ö–ò:")
        print(f"   –í—Å–µ–≥–æ –Ω–∞—Ä—É—à–µ–Ω–∏–π: {stats['total_violations']}")
        print(f"   –í—ã—Å–æ–∫–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å: {stats['high_severity']}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å: {stats['medium_severity']}")
        print(f"   –ù–∏–∑–∫–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å: {stats['low_severity']}")
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞—Ä—É—à–µ–Ω–∏—è—Ö
        if all_violations:
            print(f"\nüìã –î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø –ù–ê–†–£–®–ï–ù–ò–ô:")
            for i, violation in enumerate(all_violations, 1):
                print(f"   {i}. [{violation['severity'].upper()}] {violation['violation']}")
                if 'details' in violation:
                    print(f"      üìç {violation['details']}")
        else:
            print(f"\nüéâ –î–æ–∫—É–º–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—Å–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –¢–ó!")
        
        return {
            'violations': all_violations,
            'statistics': stats,
            'is_compliant': len(all_violations) == 0
        }
# =============================================================================
# FLASK APP
# =============================================================================

# Initialize analyzers
doc_analyzer = DocumentAnalyzer()
rule_engine = RuleEngine()

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in {'pdf'}

def generate_red_pencil_report(analysis_result: dict) -> dict:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ '–ö—Ä–∞—Å–Ω—ã–π –∫–∞—Ä–∞–Ω–¥–∞—à'"""
    violations = analysis_result.get('violations', [])
    
    report = {
        'summary': {
            'total_issues': len(violations),
            'compliance_status': '–°–û–û–¢–í–ï–¢–°–¢–í–£–ï–¢' if len(violations) == 0 else '–ù–ï –°–û–û–¢–í–ï–¢–°–¢–í–£–ï–¢',
            'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        },
        'detailed_issues': []
    }
    
    for i, violation in enumerate(violations, 1):
        issue = {
            'issue_number': i,
            'rule_reference': violation.get('rule_id', 'N/A'),
            'rule_text': violation.get('rule_text', 'N/A'),
            'violation_description': violation.get('violation', 'N/A'),
            'location': violation.get('location', 'N/A'),
            'quote': violation.get('quote', ''),
            'severity': violation.get('severity', 'medium').upper(),
            'recommendation': generate_recommendation(violation)
        }
        report['detailed_issues'].append(issue)
    
    return report

def generate_recommendation(violation: dict) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é"""
    rule_id = violation.get('rule_id', '')
    
    recommendations = {
        '1.1.1_code_missing': '–î–æ–±–∞–≤—å—Ç–µ –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ: –†–ù–ê–¢.301276.001–°–ë',
        '1.1.1_code_mismatch': '–ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –∫–æ–¥–æ–º',
        '1.1.1_unknown_code': '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞',
        '1.1.1_product_name': '–î–æ–±–∞–≤—å—Ç–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–∑–¥–µ–ª–∏—è –≤ –æ—Å–Ω–æ–≤–Ω—É—é –Ω–∞–¥–ø–∏—Å—å',
        '1.1.2_placement': '–ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤—ã—à–µ –æ—Å–Ω–æ–≤–Ω–æ–π –Ω–∞–¥–ø–∏—Å–∏',
        '1.1.2_width': '–£–º–µ–Ω—å—à–∏—Ç–µ —à–∏—Ä–∏–Ω—É —Å—Ç–æ–ª–±—Ü–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –¥–æ 185 –º–º'
    }
    
    return recommendations.get(rule_id, '–£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –≤—ã—è–≤–ª–µ–Ω–Ω–æ–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏')

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_document():
    if 'file' not in request.files:
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400
    
    if file and allowed_file(file.filename):
        filename = secure_filename(file.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], f"{uuid.uuid4()}_{filename}")
        file.save(file_path)
        
        print(f"üîÑ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {file_path}")
        print(f"üìè –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {os.path.getsize(file_path)} –±–∞–π—Ç")
        
        try:
            print(f"üîç –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞: {filename}")
            
            # Step 1: Extract text using NEW analyzer
            print("üìÑ –í–´–ó–û–í extract_text_from_pdf...")
            text_data = doc_analyzer.extract_text_from_pdf(file_path)
            print("üìÑ extract_text_from_pdf –∑–∞–≤–µ—Ä—à–µ–Ω")
            
            # Prepare document data for rule checking
            document_data = {
                'text_data': text_data,
                'metadata': {
                    'filename': filename,
                    'analysis_date': datetime.now().isoformat(),
                    'total_pages': text_data.get('total_pages', 0)
                }
            }
            
            # Step 2: Run NEW rule checks only
            print("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª –∏–∑ –¢–ó...")
            analysis_result = rule_engine.run_all_checks(document_data)
            
            # Step 3: Generate "Red Pencil" report
            print("üìä –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞...")
            red_pencil_report = generate_red_pencil_report(analysis_result)
            
            # Clean up uploaded file
            os.remove(file_path)
            
            print(f"üéâ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –ó–∞–º–µ—á–∞–Ω–∏–π: {len(analysis_result['violations'])}")
            
            return jsonify({
                'success': True,
                'analysis_result': analysis_result,
                'red_pencil_report': red_pencil_report,
                'document_metadata': document_data['metadata']
            })
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
            # Clean up on error
            if os.path.exists(file_path):
                os.remove(file_path)
            return jsonify({'error': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}'}), 500
    
    return jsonify({'error': '–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞. –†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ PDF.'}), 400

@app.route('/report', methods=['POST'])
def generate_report():
    data = request.get_json()
    red_pencil_report = data.get('red_pencil_report')
    
    if not red_pencil_report:
        return jsonify({'error': 'No report data provided'}), 400
    
    # Generate downloadable report
    report_text = generate_text_report(red_pencil_report)
    
    return jsonify({
        'report_text': report_text,
        'download_url': '/download/report.txt'
    })

def generate_text_report(red_pencil_report: dict) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
    report_lines = []
    
    summary = red_pencil_report.get('summary', {})
    report_lines.append("=" * 60)
    report_lines.append("–û–¢–ß–ï–¢ –ù–û–†–ú–û–ö–û–ù–¢–†–û–õ–Ø (–ü–û –¢–ó)")
    report_lines.append("=" * 60)
    report_lines.append(f"–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {summary.get('analysis_date', 'N/A')}")
    report_lines.append(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–º–µ—á–∞–Ω–∏–π: {summary.get('total_issues', 0)}")
    report_lines.append(f"–°—Ç–∞—Ç—É—Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {summary.get('compliance_status', 'N/A')}")
    report_lines.append("")
    
    issues = red_pencil_report.get('detailed_issues', [])
    if issues:
        report_lines.append("–î–ï–¢–ê–õ–¨–ù–´–ï –ó–ê–ú–ï–ß–ê–ù–ò–Ø:")
        report_lines.append("-" * 60)
        
        for issue in issues:
            report_lines.append(f"{issue['issue_number']}. [{issue['severity']}] {issue['violation_description']}")
            report_lines.append(f"   –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {issue['location']}")
            report_lines.append(f"   –ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {issue['rule_reference']}")
            report_lines.append(f"   –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ: {issue['rule_text']}")
            if issue['quote']:
                report_lines.append(f"   –¶–∏—Ç–∞—Ç–∞: {issue['quote']}")
            report_lines.append(f"   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {issue['recommendation']}")
            report_lines.append("")
    else:
        report_lines.append("–ó–ê–ú–ï–ß–ê–ù–ò–ô –ù–ï –í–´–Ø–í–õ–ï–ù–û")
        report_lines.append("–î–æ–∫—É–º–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º")
    
    report_lines.append("=" * 60)
    report_lines.append("–ö–æ–Ω–µ—Ü –æ—Ç—á–µ—Ç–∞")
    
    return "\n".join(report_lines)

if __name__ == '__main__':
    print("üöÄ Starting NormControl System...")
    print("üìä Access the application at: http://localhost:5000")
    print("üîß Debug mode: ON")
    print(f"üìö PDF processing: {'PyMuPDF' if PYMUPDF_AVAILABLE else 'PDFPlumber' if PDFPLUMBER_AVAILABLE else 'OCR only'}")
    print("‚úÖ –ü—Ä–æ–≤–µ—Ä—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏–∑ –¢–ó:")
    print("   1.1.1 - –û—Å–Ω–æ–≤–Ω–∞—è –Ω–∞–¥–ø–∏—Å—å (–∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ)")
    print("   1.1.2 - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (—Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∏ —à–∏—Ä–∏–Ω–∞)")
    print("=" * 60)
    app.run(host='0.0.0.0', port=5000, debug=True)